{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar to the 'CNN' notebook, but will use pure tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "import tensorflow as tf\n",
    "#sess = tf.InteractiveSession()\n",
    "import numpy as np\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkvkfiDN/okZBD1cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a4be710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "digits.target_cat = tf.one_hot(digits.target, 10)\n",
    "\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images\n",
    "X_train = data[:n_samples // 2]\n",
    "X_test = data[n_samples // 2:]\n",
    "y_train = digits.target_cat[:n_samples // 2]\n",
    "y_test = digits.target_cat[n_samples // 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEQCAYAAADlK+DYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naFAAAJf+D5tP0qiuavZ+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11daae3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=5)\n",
    "for j in range(3):\n",
    "    for i in range(5):\n",
    "        axes[j, i].imshow(X_train[j*5 + i])\n",
    "        axes[j, i].set_xticklabels([])\n",
    "        axes[j, i].set_yticklabels([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 8, 8])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "#W = tf.Variable(tf.zeros([64, 10]))\n",
    "#b = tf.Variable(tf.zeros([10]))\n",
    "#y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the structure we want to mimic:\n",
    "<ol>\n",
    "    <li>Input: N x 8 x 8\n",
    "        <ul><li>Reshape to N x 8 x 8 x 1</li></ul>\n",
    "    <li>Convolutional (2x2, 10 features)\n",
    "        <ul><li>Weights: 2 x 2 x 1 x 10</li>\n",
    "            <li>Bias: 10</li></ul>\n",
    "    <li>Convolutional (2x2, 16 features)\n",
    "        <ul><li>Weights: 2 x 2 x 10 x 16</li>\n",
    "            <li>Bias: 16</li></ul>\n",
    "    <li>Max Pooling (2x2)\n",
    "        <ul><li>Cuts rows and cols by half</li></ul>\n",
    "    <li>Dropout (25%)\n",
    "    <li>Flatten\n",
    "        <ul><li>Reshape to N x (8x8x16/4=256)</li></ul>\n",
    "    <li>Dense (10, softmax)\n",
    "        <ul><li>Weights: 256 x 10</li>\n",
    "            <li>Bias: 10</li></ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, 8, 8, 1]) #[-1==automatic depending on next 3 dims, width, height, color channels]\n",
    "\n",
    "W_conv1 = weight_variable([2, 2, 1, 10]) #[rows, cols, input channels, num features per window]\n",
    "b_conv1 = bias_variable([10]) #1 for each output channel\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([2, 2, 10, 16]) #[rows, cols, input matches output of prev, output]\n",
    "b_conv2 = bias_variable([16])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_pool2_drop = tf.nn.dropout(h_pool2, keep_prob)\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2_drop, [-1, 256])\n",
    "W_dense3 = weight_variable([256, 10])\n",
    "b_dense3 = bias_variable([10])\n",
    "y_conv = tf.matmul(h_pool2_flat, W_dense3) + b_dense3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.06\n",
      "step 100, training accuracy 0.12\n",
      "step 200, training accuracy 0.45\n",
      "step 300, training accuracy 0.53\n",
      "step 400, training accuracy 0.68\n",
      "step 500, training accuracy 0.91\n",
      "step 600, training accuracy 0.89\n",
      "step 700, training accuracy 0.86\n",
      "step 800, training accuracy 0.82\n",
      "step 900, training accuracy 0.95\n",
      "step 1000, training accuracy 0.9\n",
      "step 1100, training accuracy 0.92\n",
      "step 1200, training accuracy 0.91\n",
      "step 1300, training accuracy 0.95\n",
      "step 1400, training accuracy 0.93\n",
      "step 1500, training accuracy 0.97\n",
      "step 1600, training accuracy 0.97\n",
      "step 1700, training accuracy 0.94\n",
      "step 1800, training accuracy 0.99\n",
      "step 1900, training accuracy 0.96\n",
      "test accuracy 0.94327\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(2000):\n",
    "        indices = np.random.randint(X_train.shape[0], size=100)\n",
    "        batch_xs = X_train[indices, :]\n",
    "        batch_ys = sess.run(tf.gather(y_train, indices))\n",
    "        batch = [batch_xs, batch_ys]\n",
    "        if i % 100 == 0:\n",
    "            pass\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: X_test, y_: sess.run(y_test), keep_prob: 1.0}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like it got to around 90% accuracy within 1000 iterations and is already around 95% in 2000. The TensorFlow example used a larger network (an extra pooling layer, an extra dense layer, 2-4x larger convolutional layers, and final dense layers with ~10x as many features to get to ~99.7%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
