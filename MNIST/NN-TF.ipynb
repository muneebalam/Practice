{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar to the 'NN' notebook, but will use pure tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkvkfiDN/okZBD1cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e0834a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "digits.target_cat = tf.one_hot(digits.target, 10)\n",
    "\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "X_train = data[:n_samples // 2].astype(np.float32)\n",
    "X_test = data[n_samples // 2:].astype(np.float32)\n",
    "y_train = digits.target_cat[:n_samples // 2]\n",
    "y_test = digits.target_cat[n_samples // 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 64])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "W = tf.Variable(tf.zeros([64, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()\n",
    "for _ in range(1000):\n",
    "    indices = np.random.randint(X_train.shape[0], size=100)\n",
    "    batch_xs = X_train[indices, :]\n",
    "    batch_ys = sess.run(tf.gather(y_train, indices))\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935484\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(accuracy.eval(feed_dict={x: X_test, y_: y_test.eval()})) #.eval() converts from TF tensor to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
